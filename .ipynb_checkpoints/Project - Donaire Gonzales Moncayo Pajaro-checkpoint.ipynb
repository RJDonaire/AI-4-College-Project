{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-Cell Epitope Prediction using Attention-Based LSTM\n",
    "\n",
    "### Group 7 Members:\n",
    "\n",
    "* Donaire, Rudnick James\n",
    "\n",
    "* Gonzales, Ryan Joseph\n",
    "\n",
    "* Moncayo, Ethan Andrew\n",
    "\n",
    "* Pajaro, Randall Joseph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "\n",
    "B-Cells / B-Lymphocytes are a type of white blood cells that functions as a cell that produces antibody molecules which are responsible for humoral immune response (fluid-related substances). \n",
    "\n",
    "Epitopes are regions in a protein / peptide that the antigen recognizes. These are areas in which the immune response of our body will recognize and are susceptible for antibodies to lock with (think of it as a lock and key process).\n",
    "\n",
    "Epitope Prediction is a process in bioinformatics in which it identifies regions of a certain cell where antibodies can latch onto and neutralize its functions. This process can be used to develop epitope-based vaccine of various viruses such as SARS-CoV or H1V1.\n",
    "\n",
    "The use of Attention-based LSTM to identify these epitope regions in a particular protein sequence requires the task to identify important points within the protein sequence alongside the chemical and structural features of that particular protein and peptide sequeunces. \n",
    "\n",
    "This project is based on the study of Toshiaki, N. et al [1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:05:25.076499Z",
     "start_time": "2021-03-26T14:05:23.018321Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sgt import SGT\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Concatenate, LSTM, Dense, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from attention import Attention\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:05:25.283515Z",
     "start_time": "2021-03-26T14:05:25.079500Z"
    }
   },
   "outputs": [],
   "source": [
    "sars_csv = pd.read_csv('input_sars.csv')\n",
    "bcell_csv = pd.read_csv('input_bcell.csv')\n",
    "\n",
    "sars = sars_csv.copy()\n",
    "b_cell = bcell_csv.copy()\n",
    "\n",
    "df = pd.concat([sars,b_cell], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:05:25.331521Z",
     "start_time": "2021-03-26T14:05:25.302516Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:05:25.410524Z",
     "start_time": "2021-03-26T14:05:25.335519Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:05:25.426525Z",
     "start_time": "2021-03-26T14:05:25.412526Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:05:28.115727Z",
     "start_time": "2021-03-26T14:05:25.432528Z"
    }
   },
   "outputs": [],
   "source": [
    "epitopes = df['target'].astype(\"bool\").values\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16,8))\n",
    "\n",
    "ax = [x for a in ax for x in a]\n",
    "\n",
    "for i,name in enumerate([\"chou_fasman\",\"emini\",\"kolaskar_tongaonkar\",\"parker\"]):\n",
    "    value = df[name]\n",
    "    sns.histplot(value[~epitopes],\n",
    "                 ax = ax[i],\n",
    "                 color = 'y')\n",
    "    sns.histplot(value[epitopes],\n",
    "                 ax = ax[i],\n",
    "                 color = 'b')\n",
    "    ax[i].set_xlabel(name, \n",
    "                     fontsize=12)\n",
    "    fig.legend(labels = [\"target 0\", \"target 1\"], \n",
    "               loc = \"right\", \n",
    "               fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:05:29.801372Z",
     "start_time": "2021-03-26T14:05:28.118728Z"
    }
   },
   "outputs": [],
   "source": [
    "epitopes = df['target'].astype(\"bool\").values\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16,8))\n",
    "\n",
    "ax = [x for a in ax for x in a]\n",
    "\n",
    "for i,name in enumerate([\"isoelectric_point\",\"aromaticity\",\"hydrophobicity\",\"stability\"]):\n",
    "    value = df[name]\n",
    "    sns.histplot(value[~epitopes],\n",
    "                 ax = ax[i],\n",
    "                 color = 'y')\n",
    "    sns.histplot(value[epitopes],\n",
    "                 ax = ax[i],\n",
    "                 color = 'b')\n",
    "    ax[i].set_xlabel(name, \n",
    "                     fontsize=12)\n",
    "    fig.legend(labels = [\"target 0\", \"target 1\"], \n",
    "               loc = \"right\", \n",
    "               fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As what is shown in here, the distribution of the class per chemical features of a protein and the peptides are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = df,\n",
    "              x = 'target',\n",
    "              palette = 'spring_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for the imbalance number of labels of epitope regions is due to the fact to the total number of proteins present in the dataset. Different proteins have different lengths that may affect the number of eptiope regions present in that sequence (hypothetically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pairplot represents the correlation of each chemical and structural features of proteins and peptides in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplifying the dataset\n",
    "\n",
    "# protein sequence\n",
    "sequence = df[['parent_protein_id', 'protein_seq', 'peptide_seq']].copy()\n",
    "\n",
    "# features\n",
    "features = df.drop(['protein_seq', 'peptide_seq'], axis = 1).copy()\n",
    "\n",
    "# target\n",
    "target = df[['parent_protein_id', 'target']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be dividng the dataset into portions: sequences of the proteins present in the dataset (for embedding later on), chemical and structural features of proteins and peptides, and the target class or the ground truth labels of epitope regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding of Protein Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding of protein sequences is important for this method. This method is similar to how embedding works in NLP. In this case, the embedding sequence will be based off on the amino acids present in the sequence. These amino acids can be seen in the image below:\n",
    "\n",
    "<img src = \"amino_acids.png\">\n",
    "\n",
    "Each letter present in the sequences represents the amino acid shown in the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = sequence.drop_duplicates(subset = ['parent_protein_id']).reset_index().drop('index', axis = 1)\n",
    "corpus = corpus[['parent_protein_id', 'protein_seq']].copy()\n",
    "corpus['protein_seq'] = corpus['protein_seq'].map(list)\n",
    "corpus.rename(columns = {'parent_protein_id': 'id', 'protein_seq': 'sequence'}, inplace = True)\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgt = SGT(kappa = 10,\n",
    "          lengthsensitive = False)\n",
    "embedding = sgt.fit_transform(corpus)\n",
    "embedding.set_index('id', inplace = True)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then apply PCA in order to reduce the dimensions of the embedded sequence into a 256-dimension vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 256)\n",
    "pca_components = pca.fit_transform(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(pca_components,\n",
    "                      columns = ['vector {0}'.format(i + 1) for i in range(256)],)\n",
    "pca_df['parent_protein_id'] = corpus['id']\n",
    "pca_cols = pca_df.columns.tolist()\n",
    "pca_cols = pca_cols[-1:] + pca_cols[:-1]\n",
    "pca_df = pca_df[pca_cols]\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(features, pca_df, how = 'inner', on = 'parent_protein_id')\n",
    "\n",
    "# separating the dataset to two inputs: vectors and features\n",
    "\n",
    "# vectors\n",
    "columns = list(features.columns)\n",
    "vectors_input = merged.drop(columns, axis = 1)\n",
    "\n",
    "# features\n",
    "features_input = merged[columns].copy()\n",
    "features_input.drop('target', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will scale the chemical and structural features of the proteins via StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling features_input values\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaling = features_input.drop(['parent_protein_id', 'start_position', 'end_position'], axis = 1).copy()\n",
    "\n",
    "scaled = scaler.fit_transform(scaling)\n",
    "\n",
    "x = pd.DataFrame(scaled)\n",
    "x.insert(0, 'start_position', features_input['start_position'])\n",
    "x.insert(1, 'end_position', features['end_position'])\n",
    "\n",
    "rename = list(features.columns)[2:]\n",
    "\n",
    "for i in range(8):\n",
    "    x.rename(columns = {i: rename[i]}, inplace = True)\n",
    "\n",
    "y = merged['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the model that is going to be used for the Attention-based LSTM architecture. It will consist of:\n",
    "\n",
    "* an LSTM layer\n",
    "* an Attention layer\n",
    "* concatenated to a FCL that accepts the vectors of protein sequences and the chemical and structural features of the protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "\n",
    "# input layer\n",
    "vector_input = Input((256, 1))\n",
    "feature_input = Input((10,))\n",
    "\n",
    "# lstm layer\n",
    "lstm_layer_1 = LSTM(128, return_sequences = True)(vector_input)\n",
    "lstm_dropout = Dropout(0.6)(lstm_layer_1)\n",
    "lstm_attention = Attention(32)(lstm_dropout)\n",
    "\n",
    "# fork layer\n",
    "concat_layer = Concatenate()([feature_input, lstm_attention])\n",
    "\n",
    "# fully-connected layer\n",
    "dense_1 = Dense(200, kernel_initializer = 'normal', activation = 'relu')(concat_layer)\n",
    "batch_normal_1 = BatchNormalization(momentum = 0.6)(dense_1)\n",
    "dropout_1 = Dropout(0.3)(batch_normal_1)\n",
    "dense_2 = Dense(100, kernel_initializer = 'uniform', activation = 'relu')(dropout_1)\n",
    "batch_normal_2 = BatchNormalization(momentum = 0.6)(dense_2)\n",
    "dropout_2 = Dropout(0.3)(batch_normal_2)\n",
    "dense_3 = Dense(40, kernel_initializer = 'uniform', activation = 'relu')(dropout_2)\n",
    "batch_normal_3 = BatchNormalization(momentum = 0.6)(dense_3)\n",
    "droput_3 = Dropout(0.3)(batch_normal_3)\n",
    "output = Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid')(droput_3)\n",
    "\n",
    "# defining model\n",
    "model = Model(inputs = [vector_input, feature_input], outputs = output)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = 'loss',\n",
    "                           patience = 2,\n",
    "                           verbose = 1)\n",
    "\n",
    "hist = model.fit([vectors_input, x], y,\n",
    "                 epochs = 100,\n",
    "                 batch_size = 32,\n",
    "                 callbacks = early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['accuracy'],\n",
    "         label = 'accuracy',\n",
    "         color = 'green')\n",
    "plt.plot(hist.history['loss'],\n",
    "         label = 'loss',\n",
    "         color = 'red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the graph, the accuracy provided by the model is around 72%, which is somewhat close to the study that this project was based on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the model to a dataset that contains a protein sequence of the Covid with no particular labels to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = pd.read_csv('input_covid.csv')\n",
    "covid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_copy = corpus.copy()\n",
    "\n",
    "sequence_pred = covid_data[['parent_protein_id', 'protein_seq', 'peptide_seq']].copy()\n",
    "\n",
    "corpus_prediction = sequence_pred.drop_duplicates(subset = ['parent_protein_id']).reset_index().drop('index', axis = 1)\n",
    "corpus_prediction = corpus_prediction[['parent_protein_id', 'protein_seq']].copy()\n",
    "corpus_prediction['protein_seq'] = corpus_prediction['protein_seq'].map(list)\n",
    "corpus_prediction.rename(columns = {'parent_protein_id': 'id', 'protein_seq': 'sequence'}, inplace = True)\n",
    "\n",
    "corpus_combine = pd.concat([corpus_copy, corpus_prediction], ignore_index = True)\n",
    "corpus_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_pred = sgt.fit_transform(corpus_combine)\n",
    "embedding_pred.set_index('id', inplace = True)\n",
    "embedding_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_two = PCA(n_components = 256)\n",
    "pca_components_two = pca_two.fit_transform(embedding_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_df_two = pd.DataFrame(pca_components_two,\n",
    "                      columns = ['vector {0}'.format(i + 1) for i in range(256)],)\n",
    "pca_df_two['parent_protein_id'] = corpus_combine['id']\n",
    "pca_cols_two = pca_df_two.columns.tolist()\n",
    "pca_cols_two = pca_cols_two[-1:] + pca_cols_two[:-1]\n",
    "vectors_test = pca_df_two[pca_cols_two]\n",
    "vectors_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_features = covid_data.drop(['protein_seq', 'peptide_seq'], axis = 1).copy()\n",
    "\n",
    "merged_input = pd.merge(vectors_test, covid_features, how = 'inner', on = 'parent_protein_id')\n",
    "\n",
    "covid_vectors = merged_input[vectors_test.columns.tolist()].copy()\n",
    "covid_vectors.drop('parent_protein_id', axis = 1, inplace = True)\n",
    "\n",
    "covid_features = merged_input[covid_features.columns.tolist()].copy()\n",
    "covid_features.drop('parent_protein_id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([covid_vectors, covid_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [1 if value > 0.5 else 0 for value in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(results, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_results = covid_data.copy()\n",
    "covid_results['predictions'] = results\n",
    "\n",
    "print('Peptide Sequences of Covid Strain in identifying locations of interest:\\n')\n",
    "for peptide in covid_results[covid_results['predictions'] == 1]['peptide_seq']:\n",
    "    print('\\t-{0}'.format(peptide))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
